{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hidden_1 = 256\n",
    "n_nodes_hidden_2 = 256\n",
    "group_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1' : np.random.rand(n_input, n_nodes_hidden_1),\n",
    "    'h2' : np.random.rand(n_nodes_hidden_1, n_nodes_hidden_2),\n",
    "    'out_w' : np.random.rand(n_nodes_hidden_2, n_classes)\n",
    "#     'h1' : np.zeros((n_input, n_nodes_hidden_1)),\n",
    "#     'h2' : np.zeros((n_nodes_hidden_1, n_nodes_hidden_2)),\n",
    "#     'out_w' : np.zeros((n_nodes_hidden_2, n_classes))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bias1' : np.random.rand(n_nodes_hidden_1),\n",
    "    'bias2' : np.random.rand(n_nodes_hidden_2),\n",
    "    'out_bias' : np.random.rand(n_classes)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unipolar Sigmoidal Function\n",
    "def sigmoidal(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # First Layer\n",
    "    global layer1_out\n",
    "    net_i = np.matmul(x, weights['h1']) + biases['bias1']\n",
    "    layer1_out = sigmoidal(net_i)\n",
    "    print(net_i)\n",
    "    \n",
    "    # Second Layer\n",
    "    global layer2_out\n",
    "    net_i = np.matmul(layer1_out, weights['h2']) + biases['bias2']\n",
    "    layer2_out = sigmoidal(net_i)\n",
    "    \n",
    "    # Output Layer\n",
    "    global output_out\n",
    "    net_i = np.matmul(layer2_out, weights['out_w']) + biases['out_bias']\n",
    "    output_out = sigmoidal(net_i)\n",
    "    \n",
    "    return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change(x, y, layer1_out, layer2_out, output_out, weights, biases):\n",
    "    \n",
    "    # weight change between second hidden layer and output layer\n",
    "    error_out = (y - output_out)\n",
    "    delta_i = (error_out) * (output_out) *(1 - output_out)\n",
    "    delta_out = np.matmul((layer2_out.T), delta_i)\n",
    "    \n",
    "    # weight change between first hidden layer and second hidden layer\n",
    "    error_h2 = np.matmul(delta_i, (weights['out_w']).T)\n",
    "    delta_l = (error_h2) * (layer2_out) *(1 - layer2_out)\n",
    "    delta_h2 = np.matmul((layer1_out.T), delta_l)\n",
    "    \n",
    "    # weight change between input layer and first hidden layer\n",
    "    error_h1 = np.matmul(delta_l, (weights['h2']).T)\n",
    "    delta_k = (error_h1) * (layer1_out) *(1 - layer1_out)\n",
    "    delta_h1 = np.matmul((x.T), delta_k)\n",
    "    \n",
    "    # weight change for next iteration\n",
    "    weights['out_w'] += delta_out\n",
    "    weights['h2'] += delta_h2\n",
    "    weights['h1'] += delta_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_out = None\n",
    "layer2_out = None\n",
    "output_out = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, error : 54.490000\n",
      "Epoch : 2, error : 54.480000\n",
      "Epoch : 3, error : 54.380000\n",
      "Epoch : 4, error : 54.490000\n",
      "Epoch : 5, error : 54.530000\n",
      "Epoch : 6, error : 54.380000\n",
      "Epoch : 7, error : 54.360000\n",
      "Epoch : 8, error : 54.520000\n",
      "Epoch : 9, error : 54.350000\n",
      "Epoch : 10, error : 54.450000\n",
      "Epoch : 11, error : 54.520000\n",
      "Epoch : 12, error : 54.380000\n",
      "Epoch : 13, error : 54.380000\n",
      "Epoch : 14, error : 54.590000\n",
      "Epoch : 15, error : 54.350000\n",
      "Model has completed 15 epochs of training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    total_group = int(n_total_samples/group_size)\n",
    "    error = 0.00\n",
    "    \n",
    "    for i in range(total_group):\n",
    "        c = 0\n",
    "        x, y = mnist.train.next_batch(group_size)\n",
    "        x = 2 * ((x - x.min()) / (x.max() - x.min())) - 1\n",
    "        \n",
    "        # Calculation of output\n",
    "        output_out = multilayer_perceptron(x, weights, biases)\n",
    "        \n",
    "        # Changing the output to following form\n",
    "        # [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] for digit. 4\n",
    "        output_out = (output_out == output_out.max(axis=1)[:,None]).astype(int)\n",
    "        \n",
    "        c = sum(output_out.argmax(axis = 1) == y.argmax(axis = 1))\n",
    "        error += c/group_size\n",
    "        \n",
    "        # weight updation\n",
    "        weight_change(x, y, layer1_out, layer2_out, output_out, weights, biases)\n",
    "    \n",
    "    print(f\"Epoch : {epoch+1}, error : {error:.6f}\")\n",
    "\n",
    "print(f\"Model has completed {epoch+1} epochs of training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 * ((x - x.min()) / (x.max() - x.min())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-274.86807478 -296.9082876  -291.67241522 -283.4648799  -297.24178245\n",
      "  -291.41948908 -277.77806913 -288.24868849 -285.65576794 -281.15309955\n",
      "  -284.02589219 -294.85345495 -286.8418656  -277.8860578  -291.08546823\n",
      "  -295.37050371 -286.39120713 -283.91788391 -270.61544558 -280.10954895\n",
      "  -288.88869796 -288.97309908 -284.42700445 -293.56498939 -269.16361792\n",
      "  -291.95042744 -273.80095    -279.61905422 -301.09656196 -273.00136011\n",
      "  -274.3964061  -279.08153738 -275.88353418 -287.11592804 -274.08407143\n",
      "  -294.63635974 -285.45199957 -287.22501768 -284.40963106 -267.37714978\n",
      "  -287.4374522  -272.98694961 -292.8763642  -276.48256693 -293.31037925\n",
      "  -269.42524848 -275.1802499  -282.50937289 -297.7026969  -285.91861694\n",
      "  -291.87211263 -288.99903035 -279.51692445 -286.29405059 -279.63700264\n",
      "  -282.82642088 -284.00979279 -291.33448598 -281.6705555  -275.97212433\n",
      "  -277.05253928 -277.99150513 -284.18441848 -284.3930256  -282.18233655\n",
      "  -268.44184696 -281.95119566 -279.35979837 -284.24036494 -288.01253579\n",
      "  -278.4700537  -292.12476825 -281.9609782  -286.4414284  -272.59502486\n",
      "  -284.80399489 -300.15951622 -277.28757369 -288.55865692 -283.78533388\n",
      "  -289.18222249 -279.24687986 -282.32177742 -287.43207856 -293.07983484\n",
      "  -289.87914598 -290.14099217 -280.69431912 -287.2999342  -278.98082304\n",
      "  -281.12938717 -289.55157137 -278.94399485 -281.29360657 -297.60377574\n",
      "  -282.19982607 -275.17684057 -305.79074635 -282.95234851 -279.67499515\n",
      "  -284.78976296 -292.28795658 -280.61563997 -280.11248036 -279.20135225\n",
      "  -281.35714866 -292.95257839 -280.54187466 -283.80441508 -278.99382734\n",
      "  -276.75454887 -283.67171861 -278.05422866 -298.29028596 -286.97219482\n",
      "  -280.60826206 -278.76003614 -289.26208911 -284.11529082 -295.04172626\n",
      "  -285.00089724 -273.91743573 -285.39270027 -288.98944825 -278.59987105\n",
      "  -279.78825546 -285.2602127  -289.74558374 -291.29609942 -282.27848765\n",
      "  -280.00748405 -285.42914756 -275.91097393 -280.30044013 -283.39143384\n",
      "  -272.49036144 -279.521879   -286.83849902 -279.02446794 -275.90350327\n",
      "  -289.18323604 -286.9966138  -297.42572608 -274.21656678 -297.05212423\n",
      "  -258.93082722 -267.11167399 -287.48250613 -281.0928476  -275.02517457\n",
      "  -283.32557833 -292.79578875 -284.46185534 -277.38720885 -281.10888473\n",
      "  -284.9687796  -280.09536048 -285.93348856 -282.50854287 -282.79572987\n",
      "  -288.37056781 -280.25912681 -274.46394418 -291.77543339 -283.82084801\n",
      "  -270.37014761 -279.8424626  -289.16739492 -279.00291217 -285.25430738\n",
      "  -277.72475615 -282.19522814 -287.05812891 -290.20754304 -292.05785306\n",
      "  -279.74263138 -279.632767   -289.06590955 -279.89472102 -286.02161636\n",
      "  -285.39608167 -272.86091001 -283.27892524 -290.19447996 -262.17769878\n",
      "  -286.99856714 -283.2813191  -285.29042357 -282.45608869 -284.79418634\n",
      "  -281.18365986 -296.02381555 -296.73663595 -276.06919687 -278.2943722\n",
      "  -285.94373427 -277.2649824  -284.84365802 -280.6762799  -281.42761908\n",
      "  -282.24989976 -288.45721677 -296.5883101  -277.57905061 -276.46716207\n",
      "  -291.60305865 -285.95281359 -296.15994788 -288.63405075 -292.46576004\n",
      "  -292.65832684 -287.08983929 -272.2974048  -287.12769466 -289.70495821\n",
      "  -278.27793944 -275.68900275 -289.709626   -273.2878157  -287.77067009\n",
      "  -298.36371484 -280.83891561 -281.68339308 -286.6062655  -265.2110312\n",
      "  -275.60874535 -284.85817452 -281.96134901 -285.18967205 -277.02038559\n",
      "  -268.08754983 -288.95701824 -282.42668903 -281.25917687 -280.77776994\n",
      "  -283.29664074 -286.1987796  -289.40309061 -281.74541678 -272.59693054\n",
      "  -276.0804716  -284.11818978 -277.52761198 -265.22585677 -271.96090895\n",
      "  -285.0292067  -285.00628633 -285.87692579 -285.12254936 -292.76811446\n",
      "  -284.33964407 -286.81824283 -277.06358549 -277.02196184 -282.36746968\n",
      "  -288.37917404]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
